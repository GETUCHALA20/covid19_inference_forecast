{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "example_script_covid19_inference",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPPZjxewmt/vsedw+EmA/QE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priesemann-Group/covid19_inference_forecast/blob/cleaning_code/scripts/example_script_covid19_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuOVdcLAgRzG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "6e603dc1-feb5-4016-b610-6f3b7625d83f"
      },
      "source": [
        "!pip install git+https://github.com/Priesemann-Group/covid19_inference_forecast.git@cleaning_code"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/Priesemann-Group/covid19_inference_forecast.git@cleaning_code\n",
            "  Cloning https://github.com/Priesemann-Group/covid19_inference_forecast.git (to revision cleaning_code) to /tmp/pip-req-build-0yysoruw\n",
            "  Running command git clone -q https://github.com/Priesemann-Group/covid19_inference_forecast.git /tmp/pip-req-build-0yysoruw\n",
            "  Running command git checkout -b cleaning_code --track origin/cleaning_code\n",
            "  Switched to a new branch 'cleaning_code'\n",
            "  Branch 'cleaning_code' set up to track remote branch 'cleaning_code' from 'origin'.\n",
            "Building wheels for collected packages: covid19-inference\n",
            "  Building wheel for covid19-inference (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for covid19-inference: filename=covid19_inference-0.0.0-cp36-none-any.whl size=5427 sha256=1740c50eb69d1f72a2ec48b87d8406c9494012bdc1f0ecf5b53b5d2fb1278637\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ckeruzsd/wheels/0b/b2/1d/7bff72ae35855db34fab454bb6b6cbce5566675e123ec2f41e\n",
            "Successfully built covid19-inference\n",
            "Installing collected packages: covid19-inference\n",
            "Successfully installed covid19-inference-0.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axj37zvyhg02",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "713ca5ed-30be-4d68-b768-fcbafbe0e1e8"
      },
      "source": [
        "import sys\n",
        "import datetime\n",
        "\n",
        "import numpy as np\n",
        "import pymc3 as pm\n",
        "\n",
        "import covid19_inference as cov19\n",
        "\n",
        "confirmed_cases = cov19.get_jhu_confirmed_cases()\n",
        "\n",
        "date_data_begin = datetime.datetime(2020,3,1)\n",
        "date_data_end   = cov19.get_last_date(confirmed_cases)\n",
        "#date_data_end   = datetime.datetime(2020,3,28)\n",
        "num_days_data = (date_data_end-date_data_begin).days\n",
        "diff_data_sim = 16 # should be significantly larger than the expected delay, in \n",
        "                   # order to always fit the same number of data points.\n",
        "num_days_future = 28\n",
        "date_begin_sim = date_data_begin - datetime.timedelta(days = diff_data_sim)\n",
        "date_end_sim   = date_data_end   + datetime.timedelta(days = num_days_future)\n",
        "num_days_sim = (date_end_sim-date_begin_sim).days\n",
        "\n",
        "\n",
        "cases_obs = cov19.filter_one_country(confirmed_cases, 'Germany',\n",
        "                                     date_data_begin, date_data_end)\n",
        "\n",
        "change_points = [dict(prior_mean_date_begin_transient = datetime.datetime(2020,3,9),\n",
        "                      prior_median_λ = 0.2),\n",
        "                 dict(prior_mean_date_begin_transient = datetime.datetime(2020,3,16),\n",
        "                      prior_sigma_date_begin_transient = 1,\n",
        "                      prior_median_λ = 1/8,\n",
        "                      prior_sigma_λ = 0.2),\n",
        "                 dict(prior_mean_date_begin_transient = datetime.datetime(2020,3,23),\n",
        "                      prior_sigma_date_begin_transient = 1,\n",
        "                      prior_median_λ = 1/8/2,\n",
        "                      prior_sigma_λ = 0.2)]\n",
        "\n",
        "model = cov19.SIR_model_with_change_points(np.diff(cases_obs),\n",
        "                                                       change_points,\n",
        "                                                       date_begin_sim,\n",
        "                                                       num_days_sim,\n",
        "                                                       diff_data_sim)\n",
        "\n",
        "trace = pm.sample(model=model, init='advi+adapt_diag')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Auto-assigning NUTS sampler...\n",
            "Initializing NUTS using advi...\n",
            "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
            "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
            "Average Loss = 306.55:   6%|▋         | 12992/200000 [00:41<10:03, 309.93it/s]\n",
            "Convergence achieved at 13000\n",
            "Interrupted at 12,999 [6%]: Average Loss = 392.69\n",
            "Sequential sampling (2 chains in 1 job)\n",
            "NUTS: [σ_obs, delay, μ, transient_len_2, transient_len_1, transient_len_0, transient_begin_2, transient_begin_1, transient_begin_0, λ_3, λ_2, λ_1, λ_0, I_begin]\n",
            "100%|██████████| 1000/1000 [04:43<00:00,  3.52it/s]\n",
            "100%|██████████| 1000/1000 [04:19<00:00,  3.85it/s]\n",
            "The estimated number of effective samples is smaller than 200 for some parameters.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MultiTrace: 2 chains, 500 iterations, 27 variables>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    }
  ]
}